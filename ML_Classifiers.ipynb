{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42b6a166",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a3f9188",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from performance_metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54c7848",
   "metadata": {},
   "source": [
    "# Load and Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baf9c911",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_location_1 = 'Data/project3_dataset1.txt'\n",
    "file_location_2 = 'Data/project3_dataset2.txt'\n",
    "    \n",
    "\n",
    "dataset_1 = pd.read_csv(file_location_1, header=None, sep='\\t')\n",
    "dataset_2 = pd.read_csv(file_location_2, header=None, sep='\\t')\n",
    "    \n",
    "dataset_2[4] = dataset_2[4].replace(['Present','Absent'], [0,1]) \n",
    "    \n",
    "dataset_1 = dataset_1.to_numpy()\n",
    "dataset_2 = dataset_2.to_numpy()\n",
    "#print(len(dataset_1))    \n",
    "data_1 = dataset_1[:,:-1]\n",
    "label_1 = np.array(dataset_1[:,-1], dtype='int')\n",
    "    \n",
    "    \n",
    "data_2 = dataset_2[:,:-1]\n",
    "label_2 = np.array(dataset_2[:,-1], dtype='int')\n",
    "    \n",
    "# We consider 80% data from training and remaining 20% for testing    \n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(data_1, label_1, test_size=0.20, random_state=42, stratify=label_1)\n",
    "data_2 = dataset_2[:,:-1]\n",
    "label_2 = np.array(dataset_2[:,-1], dtype='int')\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(data_2, label_2, test_size=0.20, random_state=42, stratify=label_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a25177",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2fd0f21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 100.0, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'penalty' : ['l1','l2'], \n",
    "    'C'       : np.logspace(-3,3,7),\n",
    "    'solver'  : ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "    'max_iter': [10, 50, 100]\n",
    "}\n",
    "\n",
    "log_reg = LogisticRegression(random_state=43)\n",
    "GS = GridSearchCV(estimator=log_reg,param_grid=params,cv=10)\n",
    "\n",
    "### For dataset 1\n",
    "GS.fit(X1_train, y1_train)\n",
    "\n",
    "print('Best Parameters:',GS.best_params_,end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6ffc1118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.956140350877193, 'precision': 0.9560729421281235, 'recall': 0.956140350877193, 'f1': 0.9560273762928301, 'roc_auc': 0.9503968253968254}\n"
     ]
    }
   ],
   "source": [
    "#training the Logistic Regression classifier with best parameters and whole training set \n",
    "log_reg = LogisticRegression(random_state=43, penalty='l1', C=100, solver='liblinear', max_iter = 50)\n",
    "log_reg.fit(X1_train, y1_train)\n",
    "y_pred = log_reg.predict(X1_test)\n",
    "performance = calculate_performance(y_pred, y1_test)\n",
    "\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e3f8416c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.055\n",
      "Bias: 0.033\n",
      "Variance: 0.022\n"
     ]
    }
   ],
   "source": [
    "# bias and varience calculation for dataset 1\n",
    "mse, bias, var = bias_variance_decomp(log_reg, X1_train, y1_train, X1_test, y1_test, loss='mse', num_rounds=200, random_seed=43)\n",
    "# summarize results\n",
    "print('MSE: %.3f' % mse)\n",
    "print('Bias: %.3f' % bias)\n",
    "print('Variance: %.3f' % var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "cf6f7da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 10.0, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "\n",
      "Best Score: 0.7288288288288288\n"
     ]
    }
   ],
   "source": [
    "### For dataset 2\n",
    "GS.fit(X2_train, y2_train)\n",
    "\n",
    "print('Best Parameters:',GS.best_params_,end='\\n\\n')\n",
    "print('Best Score:',GS.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9f2560bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.6989247311827957, 'precision': 0.6855228299828581, 'recall': 0.6989247311827957, 'f1': 0.6866832092638544, 'roc_auc': 0.6367827868852459}\n"
     ]
    }
   ],
   "source": [
    "#training the Logistic Regression classifier with best parameters and whole training set \n",
    "log_reg = LogisticRegression(random_state=43, penalty='l2', C=10, solver='lbfgs', max_iter = 100)\n",
    "log_reg.fit(X2_train, y2_train)\n",
    "y_pred = log_reg.predict(X2_test)\n",
    "performance = calculate_performance(y_pred, y2_test)\n",
    "\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9813ff14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.275\n",
      "Bias: 0.215\n",
      "Variance: 0.060\n"
     ]
    }
   ],
   "source": [
    "# bias and varience calculation for dataset 2\n",
    "mse, bias, var = bias_variance_decomp(log_reg, X2_train, y2_train, X2_test, y2_test, loss='mse', num_rounds=200, random_seed=43)\n",
    "# summarize results\n",
    "print('MSE: %.3f' % mse)\n",
    "print('Bias: %.3f' % bias)\n",
    "print('Variance: %.3f' % var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e578ad84",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "90faa733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_neighbors': 7}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "\n",
    "k_range = list(range(1, 31))\n",
    "params = dict(n_neighbors=k_range)\n",
    "\n",
    "  \n",
    "GS = GridSearchCV(estimator=knn,param_grid=params,cv=10)\n",
    "\n",
    "### For dataset 1\n",
    "GS.fit(X1_train, y1_train)\n",
    "\n",
    "print('Best Parameters:',GS.best_params_,end='\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ca3bc997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.9210526315789473, 'precision': 0.9234172387490467, 'recall': 0.9210526315789473, 'f1': 0.9215739274819476, 'roc_auc': 0.9226190476190476}\n"
     ]
    }
   ],
   "source": [
    "#training the Logistic Regression classifier with best parameters and whole training set \n",
    "knn = KNeighborsClassifier(n_neighbors = 7)\n",
    "knn.fit(X1_train, y1_train)\n",
    "y_pred = knn.predict(X1_test)\n",
    "performance = calculate_performance(y_pred, y1_test)\n",
    "\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "49a1dac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.083\n",
      "Bias: 0.060\n",
      "Variance: 0.023\n"
     ]
    }
   ],
   "source": [
    "# bias and varience calculation for dataset 1\n",
    "mse, bias, var = bias_variance_decomp(knn, X1_train, y1_train, X1_test, y1_test, loss='mse', num_rounds=200, random_seed=43)\n",
    "# summarize results\n",
    "print('MSE: %.3f' % mse)\n",
    "print('Bias: %.3f' % bias)\n",
    "print('Variance: %.3f' % var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "a6ed0636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_neighbors': 16}\n",
      "\n",
      "Best Score: 0.6695945945945946\n"
     ]
    }
   ],
   "source": [
    "### For dataset 2\n",
    "GS.fit(X2_train, y2_train)\n",
    "\n",
    "print('Best Parameters:',GS.best_params_,end='\\n\\n')\n",
    "print('Best Score:',GS.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "a5e54a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.7204301075268817, 'precision': 0.7277313155449356, 'recall': 0.7204301075268817, 'f1': 0.6765795161978715, 'roc_auc': 0.6160348360655737}\n"
     ]
    }
   ],
   "source": [
    "#training the Logistic Regression classifier with best parameters and whole training set \n",
    "knn = KNeighborsClassifier(n_neighbors = 20)\n",
    "knn.fit(X2_train, y2_train)\n",
    "y_pred = knn.predict(X2_test)\n",
    "performance = calculate_performance(y_pred, y2_test)\n",
    "\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "eff78d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.289\n",
      "Bias: 0.204\n",
      "Variance: 0.085\n"
     ]
    }
   ],
   "source": [
    "# bias and varience calculation for dataset 2\n",
    "mse, bias, var = bias_variance_decomp(knn, X2_train, y2_train, X2_test, y2_test, loss='mse', num_rounds=200, random_seed=43)\n",
    "# summarize results\n",
    "print('MSE: %.3f' % mse)\n",
    "print('Bias: %.3f' % bias)\n",
    "print('Variance: %.3f' % var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093e2a42",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce278fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 1, 'degree': 2, 'gamma': 0.1, 'kernel': 'linear'}\n",
      "\n",
      "Best Score: 0.9647342995169081\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(random_state=43)\n",
    "\n",
    "#params = {'C':[0.1,1,100,1000],\n",
    "#         'kernel':['rbf','poly','sigmoid','linear'],\n",
    "#         'degree':[1,2,3,4,5,6],\n",
    "#         'gamma': [1, 0.1, 0.01, 0.001, 0.0001]}\n",
    "\n",
    "params = {'C':[0.1,1,100], \n",
    "         'kernel':['rbf','sigmoid','linear'],\n",
    "         'degree':[2,4,6],\n",
    "         'gamma': [0.1, 0.001, 0.0001]}\n",
    "\n",
    "GS = GridSearchCV(estimator=svc,param_grid=params,cv=10)\n",
    "\n",
    "#### For dataset 1\n",
    "GS.fit(X1_train, y1_train)\n",
    "\n",
    "print('Best Parameters:',GS.best_params_,end='\\n\\n')\n",
    "print('Best Score:',GS.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a862d50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.956140350877193, 'precision': 0.9565052493664558, 'recall': 0.956140350877193, 'f1': 0.956244993396696, 'roc_auc': 0.9553571428571429}\n"
     ]
    }
   ],
   "source": [
    "#training the decision tree with best parameters and whole training set \n",
    "svc = SVC(random_state=43, C = 1, kernel = 'linear' , degree = 2, gamma = 0.0001)\n",
    "svc.fit(X1_train, y1_train)\n",
    "y_pred = svc.predict(X1_test)\n",
    "performance = calculate_performance(y_pred, y1_test)\n",
    "\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "312de065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.051\n",
      "Bias: 0.033\n",
      "Variance: 0.018\n"
     ]
    }
   ],
   "source": [
    "# bias and varience calculation for dataset 1\n",
    "mse, bias, var = bias_variance_decomp(svc, X1_train, y1_train, X1_test, y1_test, loss='mse', num_rounds=200, random_seed=43)\n",
    "# summarize results\n",
    "print('MSE: %.3f' % mse)\n",
    "print('Bias: %.3f' % bias)\n",
    "print('Variance: %.3f' % var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "523989c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 0.1, 'degree': 2, 'gamma': 0.1, 'kernel': 'linear'}\n",
      "\n",
      "Best Score: 0.7126126126126127\n"
     ]
    }
   ],
   "source": [
    "#### For dataset 2\n",
    "GS.fit(X2_train, y2_train)\n",
    "\n",
    "print('Best Parameters:',GS.best_params_,end='\\n\\n')\n",
    "print('Best Score:',GS.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "458cbe69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.7311827956989247, 'precision': 0.7210245107860817, 'recall': 0.7311827956989247, 'f1': 0.7184228395752651, 'roc_auc': 0.6688012295081966}\n"
     ]
    }
   ],
   "source": [
    "#training the decision tree with best parameters and whole training set \n",
    "svc = SVC(random_state=43, C = 0.1, kernel = 'linear', degree = 2 , gamma = 0.1 )\n",
    "svc.fit(X2_train, y2_train)\n",
    "y_pred = svc.predict(X2_test)\n",
    "performance = calculate_performance(y_pred, y2_test)\n",
    "\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0a328aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.259\n",
      "Bias: 0.196\n",
      "Variance: 0.064\n"
     ]
    }
   ],
   "source": [
    "# bias and varience calculation for dataset 2\n",
    "mse, bias, var = bias_variance_decomp(svc, X2_train, y2_train, X2_test, y2_test, loss='mse', num_rounds=200, random_seed=43)\n",
    "# summarize results\n",
    "print('MSE: %.3f' % mse)\n",
    "print('Bias: %.3f' % bias)\n",
    "print('Variance: %.3f' % var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c8d02d",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dc37696a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'criterion': 'gini', 'max_depth': 7, 'min_samples_leaf': 5, 'min_samples_split': 8}\n",
      "\n",
      "Best Score: 0.9471014492753623\n"
     ]
    }
   ],
   "source": [
    "decision_tree = DecisionTreeClassifier(random_state=43)\n",
    "\n",
    "params = {'max_depth':[3,5,7,10,15],\n",
    "          'min_samples_leaf':[3,5,10,15,20],\n",
    "          'min_samples_split':[8,10,12,18,20,16],\n",
    "          'criterion':['gini','entropy']}\n",
    "GS = GridSearchCV(estimator=decision_tree,param_grid=params,cv=10)\n",
    "\n",
    "#### For dataset 1\n",
    "GS.fit(X1_train, y1_train)\n",
    "\n",
    "print('Best Parameters:',GS.best_params_,end='\\n\\n')\n",
    "print('Best Score:',GS.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a7e443dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.9210526315789473, 'precision': 0.9215784301894598, 'recall': 0.9210526315789473, 'f1': 0.9212409881140532, 'roc_auc': 0.9176587301587301}\n"
     ]
    }
   ],
   "source": [
    "#training the decision tree with best parameters and whole training set \n",
    "decision_tree = DecisionTreeClassifier(random_state=43, criterion='gini', max_depth=7, min_samples_leaf=5, min_samples_split=8)\n",
    "decision_tree.fit(X1_train, y1_train)\n",
    "y_pred = decision_tree.predict(X1_test)\n",
    "performance = calculate_performance(y_pred, y1_test)\n",
    "\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b61ab737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.080\n",
      "Bias: 0.040\n",
      "Variance: 0.040\n"
     ]
    }
   ],
   "source": [
    "# bias and varience calculation for dataset 1\n",
    "mse, bias, var = bias_variance_decomp(decision_tree, X1_train, y1_train, X1_test, y1_test, loss='mse', num_rounds=200, random_seed=43)\n",
    "# summarize results\n",
    "print('MSE: %.3f' % mse)\n",
    "print('Bias: %.3f' % bias)\n",
    "print('Variance: %.3f' % var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "afb40b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'criterion': 'gini', 'max_depth': 7, 'min_samples_leaf': 20, 'min_samples_split': 8}\n",
      "\n",
      "Best Score: 0.7152402402402404\n"
     ]
    }
   ],
   "source": [
    "### For dataset 2\n",
    "\n",
    "GS.fit(X2_train, y2_train)\n",
    "\n",
    "print('Best Parameters:',GS.best_params_,end='\\n\\n')\n",
    "print('Best Score:',GS.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1d46783e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.6236559139784946, 'precision': 0.626474421635712, 'recall': 0.6236559139784946, 'f1': 0.6249957276350238, 'roc_auc': 0.5868340163934426}\n"
     ]
    }
   ],
   "source": [
    "#training the decision tree with best parameters and whole training set \n",
    "decision_tree = DecisionTreeClassifier(random_state=43, criterion='gini', max_depth=7, min_samples_leaf=20, min_samples_split=8)\n",
    "decision_tree.fit(X2_train, y2_train)\n",
    "y_pred = decision_tree.predict(X2_test)\n",
    "performance = calculate_performance(y_pred, y2_test)\n",
    "\n",
    "print(performance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bf109da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.339\n",
      "Bias: 0.187\n",
      "Variance: 0.152\n"
     ]
    }
   ],
   "source": [
    "# bias and varience calculation for dataset 2\n",
    "mse, bias, var = bias_variance_decomp(decision_tree, X2_train, y2_train, X2_test, y2_test, loss='mse', num_rounds=200, random_seed=43)\n",
    "# summarize results\n",
    "print('MSE: %.3f' % mse)\n",
    "print('Bias: %.3f' % bias)\n",
    "print('Variance: %.3f' % var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58a62a8",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f73ccf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 7, 'max_features': 'auto', 'min_samples_leaf': 3, 'min_samples_split': 8, 'n_estimators': 300}\n",
      "\n",
      "Best Score: 0.9713526570048309\n"
     ]
    }
   ],
   "source": [
    "ran_forest = RandomForestClassifier(random_state=43)\n",
    "params = {\n",
    "          'bootstrap': [True, False],\n",
    "          'max_depth':[7,10,15],\n",
    "          'min_samples_leaf':[3, 4, 5],\n",
    "          'min_samples_split':[8,10,12],\n",
    "          'max_features': ['auto', 'sqrt'],\n",
    "          'criterion':['gini','entropy'],\n",
    "          'n_estimators': [100, 200, 300, 1000],\n",
    "          }\n",
    "\n",
    "GS = GridSearchCV(estimator=ran_forest,param_grid=params,cv=10)\n",
    "\n",
    "#### For dataset 1\n",
    "GS.fit(X1_train, y1_train)\n",
    "\n",
    "print('Best Parameters:',GS.best_params_,end='\\n\\n')\n",
    "print('Best Score:',GS.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f580862a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.9649122807017544, 'precision': 0.9658578263841422, 'recall': 0.9649122807017544, 'f1': 0.9650731808230041, 'roc_auc': 0.9672619047619049}\n"
     ]
    }
   ],
   "source": [
    "#training the random forest with best parameters and whole training set \n",
    "ran_forest = RandomForestClassifier(random_state=43, bootstrap=False, max_depth=7, min_samples_leaf=3, min_samples_split=8, max_features='auto', criterion='entropy', n_estimators=300)\n",
    "ran_forest.fit(X1_train, y1_train)\n",
    "y_pred = ran_forest.predict(X1_test)\n",
    "performance = calculate_performance(y_pred, y1_test)\n",
    "\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fbf2bf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.044\n",
      "Bias: 0.029\n",
      "Variance: 0.015\n"
     ]
    }
   ],
   "source": [
    "# bias and varience calculation for dataset 1\n",
    "mse, bias, var = bias_variance_decomp(ran_forest, X1_train, y1_train, X1_test, y1_test, loss='mse', num_rounds=200, random_seed=43)\n",
    "# summarize results\n",
    "print('MSE: %.3f' % mse)\n",
    "print('Bias: %.3f' % bias)\n",
    "print('Variance: %.3f' % var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "363e2100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 7, 'max_features': 'auto', 'min_samples_leaf': 3, 'min_samples_split': 8, 'n_estimators': 100}\n",
      "\n",
      "Best Score: 0.707057057057057\n"
     ]
    }
   ],
   "source": [
    "### For dataset 2\n",
    "\n",
    "GS.fit(X2_train, y2_train)\n",
    "\n",
    "print('Best Parameters:',GS.best_params_,end='\\n\\n')\n",
    "print('Best Score:',GS.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d72fe74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.6774193548387096, 'precision': 0.6588327619677006, 'recall': 0.6774193548387096, 'f1': 0.6597697404149017, 'roc_auc': 0.6055327868852459}\n"
     ]
    }
   ],
   "source": [
    "#training the decision tree with best parameters and whole training set \n",
    "ran_forest = RandomForestClassifier(random_state=43, bootstrap=True, max_depth=7, min_samples_leaf=3, min_samples_split=8, max_features='auto', criterion='entropy', n_estimators=100)\n",
    "ran_forest.fit(X2_train, y2_train)\n",
    "y_pred = ran_forest.predict(X2_test)\n",
    "performance = calculate_performance(y_pred, y2_test)\n",
    "\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "02b913b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.303\n",
      "Bias: 0.227\n",
      "Variance: 0.075\n"
     ]
    }
   ],
   "source": [
    "# bias and varience calculation for dataset 2\n",
    "mse, bias, var = bias_variance_decomp(ran_forest, X2_train, y2_train, X2_test, y2_test, loss='mse', num_rounds=200, random_seed=43)\n",
    "# summarize results\n",
    "print('MSE: %.3f' % mse)\n",
    "print('Bias: %.3f' % bias)\n",
    "print('Variance: %.3f' % var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949c322d",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0557031c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 1, 'n_estimators': 300}\n",
      "\n",
      "Best Score: 0.9734299516908212\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(random_state = 43, max_depth=1)\n",
    "abc = AdaBoostClassifier(base_estimator = dtc)\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [100, 200, 300, 500, 1000],\n",
    "    'learning_rate': [0.01, 0.1, 1],\n",
    "}\n",
    "\n",
    "GS = GridSearchCV(estimator=abc,param_grid=params,cv=10)\n",
    "\n",
    "#### For dataset 1\n",
    "GS.fit(X1_train, y1_train)\n",
    "\n",
    "print('Best Parameters:',GS.best_params_,end='\\n\\n')\n",
    "print('Best Score:',GS.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95926de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.9824561403508771, 'precision': 0.9824561403508771, 'recall': 0.9824561403508771, 'f1': 0.9824561403508771, 'roc_auc': 0.9811507936507938}\n"
     ]
    }
   ],
   "source": [
    "#training the adaboost with best parameters and whole training set \n",
    "abc = AdaBoostClassifier(learning_rate= 1, n_estimators= 300)\n",
    "abc.fit(X1_train, y1_train)\n",
    "y_pred = abc.predict(X1_test)\n",
    "performance = calculate_performance(y_pred, y1_test)\n",
    "\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b9bf074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.037\n",
      "Bias: 0.017\n",
      "Variance: 0.020\n"
     ]
    }
   ],
   "source": [
    "# bias and varience calculation for dataset 1\n",
    "mse, bias, var = bias_variance_decomp(abc, X1_train, y1_train, X1_test, y1_test, loss='mse', num_rounds=200, random_seed=43)\n",
    "# summarize results\n",
    "print('MSE: %.3f' % mse)\n",
    "print('Bias: %.3f' % bias)\n",
    "print('Variance: %.3f' % var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7ff15496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.01, 'n_estimators': 500}\n",
      "\n",
      "Best Score: 0.7317567567567568\n"
     ]
    }
   ],
   "source": [
    "### For dataset 2\n",
    "\n",
    "GS.fit(X2_train, y2_train)\n",
    "\n",
    "print('Best Parameters:',GS.best_params_,end='\\n\\n')\n",
    "print('Best Score:',GS.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44117153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.7204301075268817, 'precision': 0.7103942652329749, 'recall': 0.7204301075268817, 'f1': 0.6956799493991145, 'roc_auc': 0.6383196721311475}\n"
     ]
    }
   ],
   "source": [
    "#training the decision tree with best parameters and whole training set \n",
    "abc = AdaBoostClassifier(learning_rate = 0.01, n_estimators= 500)\n",
    "abc.fit(X2_train, y2_train)\n",
    "y_pred = abc.predict(X2_test)\n",
    "performance = calculate_performance(y_pred, y2_test)\n",
    "\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eaf07ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.283\n",
      "Bias: 0.206\n",
      "Variance: 0.077\n"
     ]
    }
   ],
   "source": [
    "# bias and varience calculation for dataset 2\n",
    "mse, bias, var = bias_variance_decomp(abc, X2_train, y2_train, X2_test, y2_test, loss='mse', num_rounds=200, random_seed=43)\n",
    "# summarize results\n",
    "print('MSE: %.3f' % mse)\n",
    "print('Bias: %.3f' % bias)\n",
    "print('Variance: %.3f' % var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682b3f78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (habitat)",
   "language": "python",
   "name": "habitat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
